<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Funnel</title>
    <link>https://ohsu-comp-bio.github.io/funnel/</link>
    <description>Recent content on Funnel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://ohsu-comp-bio.github.io/funnel/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AWS Batch</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/compute/aws-batch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/compute/aws-batch/</guid>
      <description>AWS Batch This guide covers deploying a Funnel server that leverages DynamoDB for storage and AWS Batch for task execution.
Setup Get started by creating a compute environment, job queue and job definition using either the Funnel CLI or the AWS Batch web console. To manage the permissions of instanced AWS Batch jobs create a new IAM role. For the Funnel configuration outlined in this document, this role will need to provide read and write access to both S3 and DynamoDB.</description>
    </item>
    
    <item>
      <title>Basic Auth</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/security/basic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/security/basic/</guid>
      <description>Basic Auth By default, a Funnel server allows open access to its API endpoints, but it can be configured to require basic password authentication. To enable this, include users and passwords in your config file:
Server: BasicAuth: - User: funnel Password: abc123 If you are using BoltDB or Badger, the Funnel worker communicates to the server via gRPC so you will also need to configure the RPC client.
RPCClient: User: funnel Password: abc123 Make sure to properly protect the configuration file so that it&amp;rsquo;s not readable by everyone:</description>
    </item>
    
    <item>
      <title>Compute</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/compute/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/compute/</guid>
      <description>Compute </description>
    </item>
    
    <item>
      <title>Databases</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/databases/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/databases/</guid>
      <description>Databases </description>
    </item>
    
    <item>
      <title>Datastore</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/databases/datastore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/databases/datastore/</guid>
      <description>Google Cloud Datastore Funnel supports storing tasks (but not scheduler data) in Google Cloud Datastore.
This implementation currently doesn&amp;rsquo;t work with Appengine, since Appengine places special requirements on the context of requests and requires a separate library.
Two entity types are used, &amp;ldquo;Task&amp;rdquo; and &amp;ldquo;TaskPart&amp;rdquo; (for larger pieces of task content, such as stdout/err logs).
Funnel will, by default, try to will try to automatically load credentials from the environment. Alternatively, you may explicitly set the credentials in the config.</description>
    </item>
    
    <item>
      <title>Deploying a cluster</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/compute/deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/compute/deployment/</guid>
      <description>Deploying a cluster This guide describes the basics of starting a cluster of Funnel nodes. This guide is a work in progress.
A node is a service which runs on each machine in a cluster. The node connects to the Funnel server and reports available resources. The Funnel scheduler process assigns tasks to nodes. When a task is assigned, a node will start a worker process. There is one worker process per task.</description>
    </item>
    
    <item>
      <title>Development</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/development/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/development/</guid>
      <description>Development </description>
    </item>
    
    <item>
      <title>Download</title>
      <link>https://ohsu-comp-bio.github.io/funnel/download/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/download/</guid>
      <description>Download 0.10.1 linux mac Windows is not supported (yet), sorry! Funnel is a single binary.
Funnel requires Docker.
Funnel is beta quality. APIs might break, bugs exist, data might be lost.
Homebrew brew tap ohsu-comp-bio/formula brew install funnel In order to build the latest code, run:
$ git clone https://github.com/ohsu-comp-bio/funnel.git $ cd funnel $ make Funnel requires Go 1.11+. Check out the development docs for more detail.
Release History See the Releases page for release history.</description>
    </item>
    
    <item>
      <title>DynamoDB</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/databases/dynamodb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/databases/dynamodb/</guid>
      <description>DynamoDB Funnel supports storing task data in DynamoDB. Storing scheduler data is not supported currently, so using the node scheduler with DynamoDB won&amp;rsquo;t work. Using AWS Batch for compute scheduling may be a better option. Funnel will, by default, try to will try to automatically load credentials from the environment. Alternatively, you may explicitly set the credentials in the config.
Available Config:
Database: dynamodb DynamoDB: # Basename to use for dynamodb tables TableBasename: &amp;#34;funnel&amp;#34; # AWS region Region: &amp;#34;us-west-2&amp;#34; # AWS Access key ID Key: &amp;#34;&amp;#34; # AWS Secret Access Key Secret: &amp;#34;&amp;#34; Known issues Dynamo does not store scheduler data.</description>
    </item>
    
    <item>
      <title>Elasticsearch</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/databases/elasticsearch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/databases/elasticsearch/</guid>
      <description>Elasticsearch Funnel supports storing tasks and scheduler data in Elasticsearch.
Config:
Database: elastic Elastic: # Prefix to use for indexes IndexPrefix: &amp;#34;funnel&amp;#34; URL: http://localhost:9200 </description>
    </item>
    
    <item>
      <title>Embedded</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/databases/boltdb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/databases/boltdb/</guid>
      <description>Embedded By default, Funnel uses an embedded database named BoltDB to store task and scheduler data. This is great for development and a simple server without external dependencies, but it doesn&amp;rsquo;t scale well to larger clusters.
Available config:
Database: boltdb BoltDB: # Path to database file Path: ./funnel-work-dir/funnel.db </description>
    </item>
    
    <item>
      <title>Events</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/events/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/events/</guid>
      <description>Events </description>
    </item>
    
    <item>
      <title>FTP</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/storage/ftp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/storage/ftp/</guid>
      <description>FTP Funnel supports download and uploading files via FTP.
Currently authentication credentials are take from the URL, e.g. ftp://username:password@ftp.host.tld. This will be improved soon to allow credentials to be added to the configuration file.
The FTP storage client is enabled by default, but may be explicitly disabled in the worker config:
FTPStorage: Disabled: false Example task { &amp;#34;name&amp;#34;: &amp;#34;Hello world&amp;#34;, &amp;#34;inputs&amp;#34;: [{ &amp;#34;url&amp;#34;: &amp;#34;ftp://my.ftpserver.xyz/hello.txt&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/inputs/hello.txt&amp;#34; }, { &amp;#34;url&amp;#34;: &amp;#34;ftp://user:mypassword123@my.ftpserver.xyz/hello.txt&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/inputs/hello.</description>
    </item>
    
    <item>
      <title>Funnel Developers</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/development/developers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/development/developers/</guid>
      <description>Developers This page contains a rough collection of notes for people wanting to build Funnel from source and/or edit the code.
Building the Funnel source Install Go 1.11+. Check the version with go version.
Ensure GOPATH is set. See the docs for help. Also, you probably want to add $GOPATH/bin to your PATH.
Clone funnel and build
$ git clone https://github.com/ohsu-comp-bio/funnel.git $ cd funnel $ make Funnel is now downloaded and installed.</description>
    </item>
    
    <item>
      <title>Google Storage</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/storage/google-storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/storage/google-storage/</guid>
      <description>Google Storage Funnel supports using Google Storage (GS) for file storage.
The Google storage client is enabled by default, and will try to automatically load credentials from the environment. Alternatively, you may explicitly set the credentials in the worker config:
GoogleStorage: Disabled: false # Path to account credentials file. AccountFile: &amp;#34;&amp;#34; Example task { &amp;#34;name&amp;#34;: &amp;#34;Hello world&amp;#34;, &amp;#34;inputs&amp;#34;: [{ &amp;#34;url&amp;#34;: &amp;#34;gs://funnel-bucket/hello.txt&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/inputs/hello.txt&amp;#34; }], &amp;#34;outputs&amp;#34;: [{ &amp;#34;url&amp;#34;: &amp;#34;gs://funnel-bucket/output.txt&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/outputs/hello-out.txt&amp;#34; }], &amp;#34;executors&amp;#34;: [{ &amp;#34;image&amp;#34;: &amp;#34;alpine&amp;#34;, &amp;#34;command&amp;#34;: [&amp;#34;cat&amp;#34;, &amp;#34;/inputs/hello.</description>
    </item>
    
    <item>
      <title>Grid Engine</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/compute/grid-engine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/compute/grid-engine/</guid>
      <description>Grid Engine Funnel can be configured to submit workers to Grid Engine by making calls to qsub.
The Funnel server needs to run on a submission node. Configure Funnel to use Grid Engine by including the following config:
It is recommended to update the submit file template so that the funnel worker run command takes a config file as an argument (e.g. funnel worker run --config /opt/funnel_config.yml --taskID {{.TaskId}})
Compute: gridengine GridEngine: Template: |#!</description>
    </item>
    
    <item>
      <title>HTCondor</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/compute/htcondor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/compute/htcondor/</guid>
      <description>HTCondor Funnel can be configured to submit workers to HTCondor by making calls to condor_submit.
The Funnel server needs to run on a submission node. Configure Funnel to use HTCondor by including the following config:
It is recommended to update the submit file template so that the funnel worker run command takes a config file as an argument (e.g. funnel worker run --config /opt/funnel_config.yml --taskID {{.TaskId}})
Compute: htcondor HTCondor: Template: |universe = vanilla getenv = True executable = funnel arguments = worker run --taskID {{.</description>
    </item>
    
    <item>
      <title>HTTP(S)</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/storage/http/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/storage/http/</guid>
      <description>HTTP(S) Funnel supports downloading files from public URLs via GET requests. No authentication mechanism is allowed. This backend can be used to fetch objects from cloud storage providers exposed using presigned URLs.
The HTTP storage client is enabled by default, but may be explicitly disabled in the worker config:
HTTPStorage: Disabled: false # Timeout for http(s) GET requests. Timeout: 30s Example task { &amp;#34;name&amp;#34;: &amp;#34;Hello world&amp;#34;, &amp;#34;inputs&amp;#34;: [{ &amp;#34;url&amp;#34;: &amp;#34;http://fakedomain.com/hello.txt&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/inputs/hello.</description>
    </item>
    
    <item>
      <title>Kafka</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/events/kafka/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/events/kafka/</guid>
      <description>Kafka Funnel supports writing task events to a Kafka topic. To use this, add an event writer to the config:
EventWriters: - kafka - log Kafka: Servers: - localhost:9092 Topic: funnel-events </description>
    </item>
    
    <item>
      <title>Kubernetes</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/compute/kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/compute/kubernetes/</guid>
      <description>Kubernetes This guide will take you through the process of setting up Funnel as a kubernetes service.
Kuberenetes Resources:
Service Deployment ConfigMap Roles and RoleBindings Job Additional Funnel deployment resources can be found here: https://github.com/ohsu-comp-bio/funnel/tree/master/deployments/kubernetes
Create a Service: funnel-service.yml
apiVersion: v1 kind: Service metadata: name: funnel spec: selector: app: funnel ports: - name: http protocol: TCP port: 8000 targetPort: 8000 - name: rpc protocol: TCP port: 9090 targetPort: 9090 Deploy it:</description>
    </item>
    
    <item>
      <title>Local</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/storage/local/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/storage/local/</guid>
      <description>Local Funnel supports using the local filesystem for file storage.
Funnel limits which directories may be accessed, by default only allowing directories under the current working directory of the Funnel worker.
Config:
LocalStorage: # Whitelist of local directory paths which Funnel is allowed to access. AllowedDirs: - ./ - /path/to/allowed/dir - ...etc Example task Files must be absolute paths in file:///path/to/file.txt URL form.
{ &amp;#34;name&amp;#34;: &amp;#34;Hello world&amp;#34;, &amp;#34;inputs&amp;#34;: [{ &amp;#34;url&amp;#34;: &amp;#34;file:///path/to/funnel-data/hello.</description>
    </item>
    
    <item>
      <title>Metrics</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/metrics/</guid>
      <description>Metrics </description>
    </item>
    
    <item>
      <title>MongoDB</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/databases/mongodb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/databases/mongodb/</guid>
      <description>MongoDB Funnel supports storing tasks and scheduler data in MongoDB.
Config:
Database: mongodb MongoDB: # Addresses for the seed servers. Addrs: - &amp;#34;localhost&amp;#34; # Database name used within MongoDB to store funnel data. Database: &amp;#34;funnel&amp;#34; Username: &amp;#34;&amp;#34; Password: &amp;#34;&amp;#34; </description>
    </item>
    
    <item>
      <title>OpenStack Swift</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/storage/swift/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/storage/swift/</guid>
      <description>OpenStack Swift Funnel supports using OpenStack Swift for file storage.
The Swift storage client is enabled by default, and will try to automatically load credentials from the environment. Alternatively, you may explicitly set the credentials in the worker config:
Swift: Disabled: false UserName: &amp;#34;&amp;#34; Password: &amp;#34;&amp;#34; AuthURL: &amp;#34;&amp;#34; TenantName: &amp;#34;&amp;#34; TenantID: &amp;#34;&amp;#34; RegionName: &amp;#34;&amp;#34; # 500 MB ChunkSizeBytes: 500000000 Example task { &amp;#34;name&amp;#34;: &amp;#34;Hello world&amp;#34;, &amp;#34;inputs&amp;#34;: [{ &amp;#34;url&amp;#34;: &amp;#34;swift://funnel-bucket/hello.txt&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/inputs/hello.</description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/</guid>
      <description>Overview Funnel makes distributed, batch processing easier by providing a simple task API and a set of components which can easily adapted to a vareity of platforms.
Task A task defines a unit of work: metadata, input files to download, a sequence of Docker containers + commands to run, output files to upload, state, and logs. The API allows you to create, get, list, and cancel tasks.
Tasks are accessed via the funnel task command.</description>
    </item>
    
    <item>
      <title>PBS/Torque</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/compute/pbs-torque/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/compute/pbs-torque/</guid>
      <description>PBS/Torque Funnel can be configured to submit workers to PBS/Torque by making calls to qsub.
The Funnel server needs to run on a submission node. Configure Funnel to use PBS by including the following config:
It is recommended to update the submit file template so that the funnel worker run command takes a config file as an argument (e.g. funnel worker run --config /opt/funnel_config.yml --taskID {{.TaskId}})
Compute: pbs PBS: Template: |#!</description>
    </item>
    
    <item>
      <title>Prometheus</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/metrics/prometheus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/metrics/prometheus/</guid>
      <description>Prometheus Prometheus is a monitoring and metrics collection service. It pulls metrics from various &amp;ldquo;exporters&amp;rdquo;, collects them in a time-series database, provides a query langauge for access that data, and integrates closely with tools such as Grafana for visualization and dashboard building.
Funnel exports these metrics:
funnel_tasks_state_count: the number of tasks in each state (queued, running, etc). funnel_nodes_state_count: the number of nodes in each state (alive, dead, draining, etc). funnel_nodes_total_cpus: the total number of CPUs available by all nodes.</description>
    </item>
    
    <item>
      <title>S3</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/storage/s3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/storage/s3/</guid>
      <description>S3 Amazon S3 Funnel supports using AWS S3 for file storage.
The Amazon S3 storage client is enabled by default, and will try to automatically load credentials from the environment. Alternatively, you may explicitly set the credentials in the worker config:
AmazonS3: Disabled: false # The maximum number of times that a request will be retried for failures. MaxRetries: 10 Key: &amp;#34;&amp;#34; Secret: &amp;#34;&amp;#34; The Amazon S3 storage client also supports SSE-KMS and SSE-C configurations.</description>
    </item>
    
    <item>
      <title>Security</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/security/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/security/</guid>
      <description>Security </description>
    </item>
    
    <item>
      <title>Slurm</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/compute/slurm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/compute/slurm/</guid>
      <description>Slurm Funnel can be configured to submit workers to Slurm by making calls to sbatch.
The Funnel server needs to run on a submission node. Configure Funnel to use Slurm by including the following config:
It is recommended to update the submit file template so that the funnel worker run command takes a config file as an argument (e.g. funnel worker run --config /opt/funnel_config.yml --taskID {{.TaskId}})
Compute: slurm Slurm: Template: |#!</description>
    </item>
    
    <item>
      <title>Storage</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/storage/</guid>
      <description>Storage </description>
    </item>
    
    <item>
      <title>Tasks</title>
      <link>https://ohsu-comp-bio.github.io/funnel/docs/tasks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ohsu-comp-bio.github.io/funnel/docs/tasks/</guid>
      <description>Tasks A task defines a unit of work:
metadata input files to download a sequence of Docker containers + commands to run, output files to upload state logs The example task below downloads a file named hello.txt from S3 and calls cat hello.txt using the alpine container. This task also writes the executor&amp;rsquo;s stdout to a file, and uploads the stdout to s3.
{ &amp;#34;name&amp;#34;: &amp;#34;Hello world&amp;#34;, &amp;#34;inputs&amp;#34;: [{ # URL to download file from.</description>
    </item>
    
  </channel>
</rss>
