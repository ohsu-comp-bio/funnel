Server:
  # Hostname of the Funnel server.
  HostName: localhost

  # Port used for HTTP communication and the web dashboard.
  HTTPPort: 8000

  # Port used for RPC communication.
  RPCPort: 9090

  # Require basic authentication for the server APIs using a password.
  # If used, make sure to properly restrict access to the config file
  # (e.g. chmod 600 funnel.config.yml)
  # Password: abc123

  # Include a "Cache-Control: no-store" HTTP header in Get/List responses
  # to prevent caching by intermediary services.
  DisableHTTPCache: true

  # Limit the size of task executor logs (stdout/err), in bytes.
  MaxExecutorLogSize: 10000 # 10 KB

  # The name of the active server database backend
  # Available backends: boltdb, dynamodb, elastic, mongodb
  Database: boltdb
  Databases:
    BoltDB:
      # Path to the database file
      Path: ./funnel-work-dir/funnel.db

    # DynamoDB:
    #   # Basename to use for dynamodb tables
    #   TableBasename: "funnel"
    #   AWS:
    #     # AWS region
    #     Region: ""
    #     # AWS Access key ID
    #     Key: ""
    #     # AWS Secret Access Key
    #     Secret: ""

    # Elastic:
    #   # Prefix to use for indexes (task, events, nodes)
    #   IndexPrefix: "funnel"
    #   # URL of the elasticsearch server.
    #   URL: http://localhost:9200

    # MongoDB:
    #   # Addrs holds the addresses for the seed servers.
    #   Addrs:
    #     - "localhost"
    #   # Database is the database name used within MongoDB to store funnel data.
    #   Database: "funnel"
    #   Username: ""
    #   Password: ""

  Logger:
    # Logging levels: debug, info, error
    Level: info
    # Write logs to this path. If empty, logs are written to stderr.
    OutputFile: ""

# The scheduler is used for the Manual compute backend. 
Scheduler:
  # How often to run a scheduler iteration.
  # In nanoseconds.
  ScheduleRate: 1000000000 # 1 second
  # How many tasks to schedule in one iteration.
  ScheduleChunk: 10
  # How long to wait between updates before marking a node dead.
  # In nanoseconds.
  NodePingTimeout: 60000000000 # 1 minute
  # How long to wait for a node to start, before marking the node dead.
  # In nanoseconds.
  NodeInitTimeout: 300000000000 # 5 minutes
  Node:
    # If empty, a node ID will be automatically generated.
    ID: ""

    # Files created during processing will be written in this directory.
    WorkDir: ./funnel-work-dir
    # If the node has been idle for longer than the timeout, it will shut down.
    # -1 means there is no timeout. 0 means timeout immediately after the first task.
    Timeout: -1

    # A Node will automatically try to detect what resources are available to it. 
    # Defining Resources in the Node configuration overrides this behavior.
    Resources:
      # CPUs available.
      # Cpus: 0

      # RAM available, in GB.
      # RamGb: 0.0

      # Disk space available, in GB.
      # DiskGb: 0.0

      # For low-level tuning.
      # How often to sync with the Funnel server.
      # In nanoseconds.
      UpdateRate: 5000000000 # 5 seconds
      # RPC timeout for update/sync call.
      # In nanoseconds.
      UpdateTimeout: 1000000000 # 1 second

      Logger:
        # Logging levels: debug, info, error
        Level: info
        # Write logs to this path. If empty, logs are written to stderr.
        OutputFile: ""


# The name of the active compute backend
# Available backends: local, htcondor, slurm, pbs, gridengine, manual, aws-batch
Backend: local

# Scheduler backend config
Backends:
  HTCondor:
    Template: |
      universe = vanilla
      getenv = True
      executable = {{.Executable}}
      arguments = worker run --config {{.Config}} --task-id {{.TaskId}}
      log = {{.WorkDir}}/condor-event-log
      error = {{.WorkDir}}/funnel-stderr
      output = {{.WorkDir}}/funnel-stdout
      should_transfer_files = YES
      when_to_transfer_output = ON_EXIT_OR_EVICT
      {{if ne .Cpus 0 -}}
      {{printf "request_cpus = %d" .Cpus}}
      {{- end}}
      {{if ne .RamGb 0.0 -}}
      {{printf "request_memory = %.0f GB" .RamGb}}
      {{- end}}
      {{if ne .DiskGb 0.0 -}}
      {{printf "request_disk = %.0f GB" .DiskGb}}
      {{- end}}

      queue

  PBS:
    Template: |
      #!bin/bash
      #PBS -N {{.NodeId}}
      #PBS -o {{.WorkDir}}/funnel-stdout
      #PBS -e {{.WorkDir}}/funnel-stderr
      {{if ne .Cpus 0 -}}
      {{printf "#PBS -l nodes=1:ppn=%d" .Cpus}}
      {{- end}}
      {{if ne .RamGb 0.0 -}}
      {{printf "#PBS -l mem=%.0fgb" .RamGb}}
      {{- end}}
      {{if ne .DiskGb 0.0 -}}
      {{printf "#PBS -l file=%.0fgb" .DiskGb}}
      {{- end}}

      {{.Executable}} worker run --config {{.Config}} --task-id {{.TaskId}}

  GridEngine:
    Template: |
      #!bin/bash
      #$ -N {{.NodeId}}
      #$ -o {{.WorkDir}}/funnel-stdout
      #$ -e {{.WorkDir}}/funnel-stderr
      #$ -l nodes=1
      {{if ne .Cpus 0 -}}
      {{printf "#$ -pe mpi %d" .Cpus}}
      {{- end}}
      {{if ne .RamGb 0.0 -}}
      {{printf "#$ -l h_vmem=%.0fG" .RamGb}}
      {{- end}}
      {{if ne .DiskGb 0.0 -}}
      {{printf "#$ -l h_fsize=%.0fG" .DiskGb}}
      {{- end}}

      {{.Executable}} worker run --config {{.Config}} --task-id {{.TaskId}}
  
  SLURM:
    Template: |
      #!/bin/bash
      #SBATCH --job-name {{.NodeId}}
      #SBATCH --ntasks 1
      #SBATCH --error {{.WorkDir}}/funnel-stderr
      #SBATCH --output {{.WorkDir}}/funnel-stdout
      {{if ne .Cpus 0 -}}
      {{printf "#SBATCH --cpus-per-task %d" .Cpus}}
      {{- end}}
      {{if ne .RamGb 0.0 -}}
      {{printf "#SBATCH --mem %.0fGB" .RamGb}}
      {{- end}}
      {{if ne .DiskGb 0.0 -}}
      {{printf "#SBATCH --tmp %.0fGB" .DiskGb}}
      {{- end}}

      {{.Executable}} worker run --config {{.Config}} --task-id {{.TaskId}}

  # Batch describes the configuration for the AWS Batch compute backend.
  Batch:
    # JobDefinition can be either a name or the Amazon Resource Name (ARN).
    JobDefinition: "funnel-job-def"
    # JobQueue can be either a name or the Amazon Resource Name (ARN).
    JobQueue: "funnel-job-queue"
    # AWS region of the specified job queue and to create the job definition in
    Region: ""
    Credentials:
      Key: ""
      Secret: ""


Worker:
  # Files created during processing will be written in this directory.
  WorkDir: ./funnel-work-dir

  # File storage systems.
  #
  # This is usually set automatically by the scheduler, but you might need this
  # if you're starting a worker manually.
  Storage:
    # Local file system.
    Local:
      # Whitelist of local directory paths which Funnel is allowed to access.
      AllowedDirs:
        - ./

    AmazonS3:
      Disabled: false
      AWS:
        # The maximum number of times that a request will be retried for failures.
        MaxRetries: 10
        # AWS Access key ID
        Key: ""
        # AWS Secret Access Key
        Secret: ""

    # S3:
    #   - Disabled: true
    #     Endpoint: ""
    #     Key: ""
    #     Secret: ""

    GS:
      Disabled: false
      # Path to account credentials file.
      # Optional. If possible, credentials will be automatically discovered
      # from the environment.
      AccountFile: ""

    # If possible, credentials will be automatically discovered
    # from the environment.
    Swift:
      Disabled: false
      UserName: ""
      Password: ""
      AuthURL: ""
      TenantName: ""
      TenantID: ""
      RegionName: ""

  # For low-level tuning.
  # How often to send task log updates to the Funnel server.
  # In nanoseconds.
  UpdateRate: 5000000000 # 5 seconds

  # Maximum task log (stdout/err) size, in bytes to buffer between updates.
  BufferSize: 10000 # 10 KB

  # The name of the active task reader backend.
  # Available backends: rpc, dynamodb, elastic, mongodb
  TaskReader: rpc
  TaskReaders:

    # DynamoDB:
    #   # Basename to use for dynamodb tables
    #   TableBasename: "funnel"
    #   AWS:
    #     # AWS region
    #     Region: ""
    #     # AWS Access key ID
    #     Key: ""
    #     # AWS Secret Access Key
    #     Secret: ""

    # Elastic:
    #   # Prefix to use for indexes (task, events, nodes)
    #   IndexPrefix: "funnel"
    #   # URL of the elasticsearch server.
    #   URL: http://localhost:9200

    # MongoDB:
    #   # Addrs holds the addresses for the seed servers.
    #   Addrs:
    #     - "localhost"
    #   # Database is the database name used within MongoDB to store funnel data.
    #   Database: "funnel"
    #   Username: ""
    #   Password: ""

  # The name of the active event writer backend.
  # Available backends: rpc, log, dynamodb, elastic, mongodb
  ActiveEventWriters: 
    - rpc
    - log
  EventWriters:
    # Write events over gRPC
    RPC:
      # RPC timeout for update/sync call.
      # In nanoseconds.
      UpdateTimeout: 1000000000 # 1 second

    # Translate events and store their content in DynamoDB.
    # DynamoDB:
    #   # Basename to use for dynamodb tables
    #   TableBasename: "funnel"
    #   AWS:
    #     # AWS region
    #     Region: ""
    #     # AWS Access key ID
    #     Key: ""
    #     # AWS Secret Access Key
    #     Secret: ""

    # Elastic:
    #   # Prefix to use for indexes (task, events, nodes)
    #   IndexPrefix: "funnel"
    #   # URL of the elasticsearch server.
    #   URL: http://localhost:9200

    # MongoDB:
    #   # Addrs holds the addresses for the seed servers.
    #   Addrs:
    #     - "localhost"
    #   # Database is the database name used within MongoDB to store funnel data.
    #   Database: "funnel"
    #   Username: ""
    #   Password: ""
      
  Logger:
    # Logging levels: debug, info, error
    Level: info
    # Write logs to this path. If empty, logs are written to stderr.
    OutputFile: ""
